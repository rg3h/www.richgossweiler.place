<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Rich Gossweiler - Perception</title>
  <link rel=stylesheet href="../../../modules/reset.css"/>
  <link rel=stylesheet href="../../../assets/fonts/openSans/openSans.css"/>
  <link rel=stylesheet href="../../../modules/main.css"/>
  <script type="module" src="../../../modules/main.js"></script>
  <script src="./perception.js"></script>
</head>
<body>
<div class=page>
    <!-- ********** perception header ********** -->
    <div class=header id=perceptionHeader>
      <!-- ********** perceptionHeaderTitle ********** -->
      <div class=headerTitle id=perceptionHeaderTitle>Rich Gossweiler</div>

      <!-- ********** perceptionHeaderDate ********** -->
      <div class=headerDate id=perceptionHeaderDate>current date</div>

      <div class=clearFloat></div>

      <!-- ********** perceptionHeaderQuote ********** -->
      <div class=headerQuote id=perceptionHeaderQuote></div>
      <div class=clearFloat></div>
    </div> <!-- header -->


<h1>Perception Lab: VR for Perception Studies</h1>

<div class=paragraphSpacer></div>

My Ph.D. (Application-independent Time Critical Rendering), was a
combination of visual perception and computer science. For example, we
would put hgh spatial frequency information in one eye and
low-spatial-frequency textures and color in the other. Thie could
potentially improve the speed of each computer (we had one per eye and a
rather ill-named <i>socket</i> connection between the two eyes).

<div class=paragraphSpacer></div>

This led to a more fundamental model around performing perception studies
in VR. This would give us one measure of how well the virtual environment
corresponded to the real world from the person's perspective as well as
provide a rapid testing environment. We could quickly iron out testing
details for a more involved real-world perception study as well as test
visual stimulii that was difficult to get in the real world.

<div class=paragraphSpacer></div>

An example of that was a
    <a href=http://goo.gl/UEjPx5> <!-- perceivingGeographicalSlant.pdf -->
geographical slant (hill) study</a> done by Denny Proffit and
Mukul Bhalla. They wanted to study the discrepancy between how steep people perceive
a hill and the actual slope (and later whether people like skiiers or
roofers might do a better job).

<div class=paragraphSpacer></div>

To conduct this test in the real world, they had to pay students and take
them to various locations around the town. Getting to steep, tall hills was
also problematic. Meanwhile we conducted a similar study in a virtual
environment. We had no problem getting people to sign up, we could quickly
test different slopes in different orders, and we could do hills much
steeper than available around town.

<div class=paragraphSpacer></div>

The resulting graphs of people's perceptions matched extremely well in the
virtual environment to those in the real world. The curve showed how
people might perceive steeper hills.  The was beneficial for helping
measure the accuracy of the virtual environment as well as helping the real
world study.

<div class=paragraphSpacer></div>

This study led us to consider constructing a virtual perception lab with an
API (in C and in python) to allow us to try out other studies quickly. It
was also well timed, since other labs, such as Georgia Tech, were
experimenting with using VR to help people get over fear of heights, with
government and company VR systems testing out its
<a href=http://goo.gl/5ZHUx7> <!-- shipboardVR.pdf -->
utility as a training mechanism</a>
(e.g. fire fight training).

<div class=spacer></div>
<img src=perceptionLabIcon.jpg />

<div class=spacer></div>

<div class=paragraphSpacer></div>

<div class=entry>
  <div class=entryTitleItalic>
    paper:
    <a href=http://goo.gl/UEjPx5> <!-- perceivingGeographicalSlant.pdf -->
      Perceiving Geographical Slant,
    </a>
  </div>
  <div class=entryDescription>
    Mukul Bhalla, Rich Gossweiler, Jonathan Midgett, Psychonomic Bulletin &
    Review, 2, 1995, 409-428.</a><br>
  </div>
</div>

<div class=entry>
  <div class=entryTitleItalic>
    paper:
      <a href=http://goo.gl/5ZHUx7> <!-- shipboardVR.pdf -->
      Shipboard VR: from damage control to design
    </a>
  </div>
  <div class=entryDescription>
    Lawrence Rosenblum, Jim Durbin, Upul Obeysekare, Linda Sibert,
    David Tate, James Templeman, Jyoti Agrawal et al., Computer Graphics
    and Applications, IEEE 16, no. 6 (1996): 10-13.
  </div>
</div>

  <br><br>
  </div> <!-- page -->
</body>
